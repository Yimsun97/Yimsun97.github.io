<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Windows下的Spyder快捷键总结]]></title>
    <url>%2F2020%2F04%2F07%2FWindows%E4%B8%8B%E7%9A%84Spyder%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[作为轻量级 IDE，Spyder 是数据分析的一大利器。升级到 4.1.1 版本后，酷炫的黑色主题外加 Kite 辅助参数补全，较之前版本又有了很大的改进，可谓更加流畅、优雅了。当然，一个强大的 IDE 怎能少得了快捷键的加持？ 不知大家都有没有这样的体验，当写代码感觉来了的时候，有时候因为需要不停地点鼠标影响了写代码的速度。这时，就体现 IDE 中快捷键的重要性了。所以说，让手留在键盘上，不需要不断地点击鼠标，实为提高写代码效率的重要一环。 本文基于网络上的一篇英文文章[1]，并对其进行了翻译、测试和整理。全文在 Win10 系统上测试通过，Spyder 版本为 4.1.1。 一键安装&amp;升级新版本 Spyder： 1conda install spyder=4.1.1 常用快捷键传统 按键 功能 按键 功能 Home 光标移至行首 End 光标移至行尾 Ctrl + ← 光标移至单词前 Ctrl + → 光标移至单词后 Ctrl + ↑ 光标移至代码块前 Ctrl + ← 光标移至代码块后 Ctrl + Home 光标移至文档最前 Ctrl + ← 光标移至文档最后 Ctrl + O 打开文件 Ctrl + N 新建文件 Ctrl + Backspace 删除前一个单词 Ctrl + Delete 删除后一个单词 导航 按键 功能 按键 功能 Ctrl + L 跳转到行 Ctrl + G 跳转到定义处 Ctrl + Tab 跳转到前一个文件 Ctrl + Shift + Tab 跳转到后一个文件 缩放和注释 按键 功能 按键 功能 Ctrl + + 放大 Ctrl + - 跳转到定义处 Ctrl + 0 跳转到前一个文件 Ctrl + 1 跳转到后一个文件 Ctrl + 4 插入块注释 Ctrl + 5 取消块注释 搜索和替换 按键 功能 按键 功能 Ctrl + F 搜索文本 Ctrl + R 替换文本 F3 搜索下一个文本 Shift + F3 搜索上一个文本 移动和增删 按键 功能 按键 功能 Alt + ↑ 移动文本至上一行 Alt + ↓ 移动文本至下一行 Ctrl + Alt + ↑ 复制当前行至上一行 Ctrl + Alt + ↓ 复制当前行至下一行 Ctrl + D 删除当前行 杂项 按键 功能 按键 功能 Alt + ↑ 移动文本至上一行 Shift + Tab 减少缩进 Ctrl + U 转换为小写 Ctrl + Shift + U 转换为大写 Ctrl + I 查看对象文档 F11 全屏模式 执行&amp;调试 按键 功能 按键 功能 F5 运行程序 F9 运行选择或当前行 Ctrl + Enter 运行当前代码段 Ctrl + F5 启动调试 Ctrl + F12 调试继续 Ctrl + Shift + F12 停止调试 Ctrl + . 重启 Ipython 核 Ctrl + T 打开新的 Ipython 控制台 转换编辑区域 按键 功能 按键 功能 Ctrl + Shift + I 跳转到 Ipython 控制台 Ctrl + Shift + E 跳转到编辑器 自定义快捷键在 Spyder 中，打开 Tools —&gt; Preferences —&gt; Keyboard shortcuts，即可自定义快捷键。 小结 快捷键看似比较繁杂、不好记忆，但通过日常的频繁使用、强化练习和正向激励，就能逐渐找到感觉，最终达到熟捻于心的程度。 用 Spyder 写代码时分代码块是一个好习惯，不仅可以使代码结构更加清晰，在写比较耗时的大程序时还能节省运行时间。代码块用 #%% 开头，与 MATLAB 类似但不一样，这样就可以用前文所述的 Ctrl + Enter 快捷键执行代码块了。 参考文献 Spyder Keyboard Shortcuts for the Editor under Windows]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bat批处理总结]]></title>
    <url>%2F2020%2F04%2F04%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[bat 批处理脚本是 Windows 系统上用于批量执行任务的脚本，其后缀名为 .bat。利用批处理文件与“胶水语言” Python 相结合，能解决很多情况下程序的自动化运行问题，为学习、科研、工作上带来很大的便利。 近来做一个科研项目，需要运行某一个模型软件数十次乃至上百次。此前对 bat 批处理的了解比较有限，借此机会完成项目的机会，对常用的 bat 脚本做了一个简单的入门学习。特此对过程中学习到的知识点作简要总结。 命令总结echo“echo”一词英文本意为“发出回声”、“产生回响”，大致相当于 Python 中的 print 函数，可以在 cmd 窗口中显示消息，也有打开和关闭回显的功能。常用的代码有以下两种： 在屏幕上打印“hello world” 1echo hello world 关闭运行命令本身的显示 1@echo off @加在其他命令行最前面，表示运行时不显示该命令行本身。 1@echo Now starting the model... call从一个批处理程序调用其他批处理程序，而不终止原来的程序。举个例子，下面的命令调用 Anaconda 的 activate.bat 脚本，使用该操作可以在 cmd 窗口中激活某一环境。 12call D:\Commonsoftware\Anaconda\Scripts\activate.batcall activate myenv 其中，myenv 是需要激活的环境名称。 pause在执行完命令后显示“请按任意键继续···”字样。该命令一般用来调试程序，确保批处理代码在执行中没有出现任何问题。常放在 bat 文件末尾和其他想终止程序的地方。 REMbat 文件注释。对应的 Notepad++ 的快捷键为 Ctrl+k （单行、多行注释）&amp; Ctrl+q （区块注释）。 if批处理中执行条件处理的语句。首先，需要了解 bat 文件中比较运算符的有效值。 运算符 描述 运算符 描述 EQU 等于 LEQ 小于或等于 NEQ 不等于 GTR 大于 LSS 小于 GEQ 大于或等于 下面来看一个例子。 123456789@echo offset /a a=123set /a b=456if %a% geq %b% ( echo %a%^&gt;=%b%) else ( echo %a%^&lt;%b% )pause 需要注意的是，if 语句后的括号必须要写在与其同一行的末尾。 此外，在进行字符串比较时，if 后加 /i 命令可强制字符串比较时忽略大小写。 choice此命令本意是显示信息并暂停批处理程序，让用户在做一些交互的选择。比如 Anaconda 中安装 Python 包时的提示是否安装的 [y/n] 就是利用的这个命令。 有时，利用此命令占用内存较小、计时较为精确的特点，可以用此命令进行计时，程序会等待特定的时间，再执行下面的命令。以下语句表示等待 10 秒再执行批处理程序。 1choice /t 10 /d y /n &gt;nul 值得注意的是，用该命令计时有个缺陷：只能计时 0~9999 秒之内的时间（约 2.7 小时，但一般情况还是够用的）。 for循环命令。直接看代码： 123456REM 1@echo offfor %%a in (1, 1, 5) do ( echo %%a)pause 执行结果： 123115 以上代码表示，变量 a 在集合 (1, 1, 5) 中进行遍历，然后回显出值。 12345@echo offfor /l %%a in (1, 1, 5) do ( echo %%a)pause 执行结果： 1234512345 以上代码表示，变量 a 从 1 开始，步长为 1，终值为 5，进行循环。 两段代码的区别在于，第二段代码在 for 循环开始时，多了 /l 参数。 setlocal启动批处理文件中环境变量的本地化。通俗地讲，该命令执行后会使得批处理程序对局部变量进行修改，而不是始终保持全局变量的值。如果这里没有看懂的话，请比较以下两段代码就清楚了： 1234567891011REM 1@echo offset /a a=123if %a% equ 123 ( set /a a=%a%*2 echo %a%) else ( echo %a% not equal to 123 )pause 执行结果为：123。 123456789101112REM 2@echo offset /a a=123setlocal enableDelayedExpansionif !a! equ 123 ( set /a a=!a!*2 echo !a!) else ( echo !a! not equal to 123 )pause 执行结果为：246。 执行结果差异的原因在于第 1 段代码没有开启环境变量的本地化，因此在设置变量值后，引用变量时仍然是全局变量的值；使用 setlocal 指令后，解决了这一问题。显然，第 2 段代码是我们预期的结果。 比较这两段代码可以发现，使用 setlocal 主要需要注意以下两点： 需要声明 setlocal enableDelayedExpansion ； 变量引用形式均为 !a! 。 taskkill结束某一进程。常用的有以下两种用法： 结束已知应用名称的某一进程； 结束已知进程码的某一进程。 以关闭 Notepad++.exe 程序为例举些例子： 12REM 1taskkill /im notepad++.exe 12REM 2taskkill /pid 1376 -t -f 进程码可以通过任务管理器查询，或者通过 cmd 运行 tasklist 获取。 参数 -t 表示结束该进程，-f 表示强制结束该进程及所有子进程。 代码总结自动化运行 IPython有时想启动 Ipython 做个简单的计算或者验证，与打开 Spyder 或者 PyCharm 等 IDE 相比，此时调出 Ipython 最为方便省时间。但打开 Anaconda Prompt 又需要输入激活环境等命令，比较麻烦。使用下面的命令可以大大简化这样的问题。 1234REM ip.batcall D:\Commonsoftware\Anaconda\Scripts\activate.batcall activate myenvcall jupyter qtconsole 如果不想把脚本防在桌面，可以配置环境变量，使用 Win+R 快捷键输入批处理文件名 ip.bat 就能方便地打开 IPython。 自动化运行 Jupyter Notebook与以上情景类似，使用以下代码，轻松打开 Jupyter Notebook： 1234567E:cd E:call D:\Commonsoftware\Anaconda\Scripts\activate.bat call activate myenvstart chrome http://localhost:8888/treecall jupyter notebookpause 默认的打开文件路径在 E 盘，当然可以根据个人情况进行修改~ 在 cmd 窗口中写 Python语句有时在命令行窗口中想做些简单的计算或文本处理，无需再打开 Python IDE，直接在 cmd 窗口中就可以写简单的 Python 程序： 1python -c "import numpy as np; print(np.arange(6))" 自动化运行模型回到最初的目的应用场景，下面是自动化运行某一模型或者应用程序的示例代码。cyc 是运行次数，ti 是模型运行一次的持续时间，start 语句是新建一个 cmd 窗口运行程序，&amp;&amp; 表示程序先后进行，即先打开程序路径再运行程序，程序中应用 Python 脚本可以进行模型的前处理和后处理。 123456789101112131415@echo offsetlocal enabledelayedexpansionset cyc=100set ti=3000call D:\anaconda3\Scripts\activate.batcall activate myenvpython model_preprocess.pyfor /l %% i in (1,1,!cyc!) do ( start cmd /c "cd ./AppPath &amp;&amp; model.exe" choice /t !ti! /d y /n &gt;nul taskkill /f /im model.exe)python model_postprocess.pyendlocaltaskkill /f /im cmd.exe 小结 通过本文，基本上对批处理有了个简单的入门，对某些参数功能不清楚时，在 cmd 窗口中输入 /? 是最简单快捷的查看文档的方式； 有些时候在网上复制的代码不能直接在命令行及批处理文件中应用，应将其转化为 ANSI 编码后查看没有乱码后运行才不会出错； 批处理文件作为 Windows 系统的自动化处理的利器，可以做到一些 Python 脚本不能做到或者不方便做到的事情，此时简单学些批处理可以大大提高工作效率和自动化水平，但是如果 Python 脚本可以做到的事采用 Python 更方便快捷，易于调试和维护。 参考文献 张亮清编著《DOS/BIOS高手真经》第2版 bat中if语句的用法 cmd-bat批处理命令延时方法]]></content>
      <categories>
        <category>程序语言</category>
      </categories>
      <tags>
        <tag>BatchFile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络Backpropagation算法入门]]></title>
    <url>%2F2019%2F11%2F24%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CBackpropagation%E7%AE%97%E6%B3%95%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[近期学习了 coursera 上 Andrew Ng 的机器学习课程[1]。总体而言，该课程是入门机器学习的绝佳教程，整体难度不大，但概括了机器学习中很多基础的概念。但弊端在于跳过了过多数学推导，导致有些问题讲解得不是很清楚。特别是在第5周课程 Neural Networks: Learning 中，虽讲解了 BP 算法的轮廓和执行过程，但没有计算图的辅助和数学公式的推导就很难理解，且出现了较多的讹误。因此写下该篇笔记，记录关于BP算法的重要学习路线和结论，以期给其他同样困惑的同学和未来的自己一些提示作用。 该笔记的写作过程中，同样参考了斋藤康毅的《深度学习入门》一书中计算图（computational graph）的叙述，和长躯鬼侠的知乎专栏矩阵求导术（上）中关于标量对矩阵导数计算的说明。 概述BP 神经网络的实现过程大体上如下： Step 1 随机产生网络参数的初始值， Step 2 计算正向传播（Forward propagation）得到预测值，进而计算损失函数的值； Step 3 通过 Backpropagation 算法计算偏导数，进而得到损失函数的梯度； Step 4 利用优化算法对参数值进行更新； Step 5 反复执行Step 2 ~ Step 4 至收敛为止。 Backpropagation 算法是计算神经网络梯度（Step 3）的重要算法，比起计算导数的差分算法，它大大提升了导数的计算速度，进而加快了神经网络的训练速度。 符号系统本篇笔记的符号系统与 coursera 课程上的基本保持一致，略有修改。简述如下： 图1为神经网络的示例图（未画出偏置项），该网络用于一个多元分类问题，共分为 $K$ 类。 图1 神经网络示例用 $L$ 表示神经网络总层数， $s_l$ 表示第 $l$ 层的神经元个数（不包括偏置项），共有 $M$ 个数据，数据记为 {\left\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(M)},y^{(M)}) \right\}}激活函数记为 h_\theta(x)\in \mathbb{R}^K$(h_\theta(x))_i$ 表示第 $i$ 个结果。 损失函数记为 $J(\Theta)$ ,表达式如下： \begin{aligned} J(\Theta)=&-\frac{1}{M}\left[\sum_{m=1}^{M} \sum_{k=1}^{K} y_{k}^{(m)} \log \left(h_{\Theta}\left(x^{(m)}\right)\right)_{k}+\left(1-y_{k}^{(m)}\right) \log \left(1-\left(h_{\Theta}\left(x^{(m)}\right)\right)_{k}\right)\right] \\ &+\frac{\lambda}{2 M} \sum_{l=1}^{L-1} \sum_{i=1}^{s_{l}} \sum_{j=1}^{s_{l+1}}\left(\Theta_{j i}^{(l)}\right)^{2} \end{aligned}式中， $M$ 为样本个数， $K$ 为分类总数， $\Theta_{ji}^{(l)}$ 为第 $l$ 层后节点编号为 $j$ 、前节点编号为 $i$ 的参数值。 记激活函数 sigmoid 函数为 $g(x)$ ，即： g(x)=\frac{1}{1+e^{-x}}记 $\delta_j^{(l)}$ 为第 $l$ 层，第 $j$ 个节点的”误差”（coursera: “error”），下面的叙述会具体解释该参数的含义。 前向传播以 one-hot 表示的单一数据 $(x,y)$ 为例，正向传播过程的表示如下： \begin{array}{l}{a^{(1)}=x\left(\operatorname{add} a_{0}^{(1)}\right)} \\ {z^{(2)}=\Theta^{(1)} a^{(1)}} \\ {a^{(2)}=g\left(z^{(2)}\right)\left(\operatorname{add} a_{0}^{(2)}\right)} \\ {z^{(3)}=\Theta^{(2)} a^{(2)}} \\ {a^{(3)}=g\left(z^{(3)}\right)\left(\operatorname{add} a_{0}^{(3)}\right)} \\ {z^{(4)}=\Theta^{(3)} a^{(3)}} \\ {a^{(4)}=h_{\Theta}(x)=g\left(z^{(4)}\right)}\end{array}本文重点是反向传播，前向传播推导从略。 反向传播先给出算法，后进行解释，最后进行推导。 算法描述coursera 课程上的算法描述如下： Step 1 Training set ${\left\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(M)},y^{(M)}) \right\}}$ Step 2 Set $\Delta_{ji}^{(l)}=0$ (for all $l,i,j$). Step 3 For $m=1,M$ ​ Set $a^{(1)}=x^{(m)}$ ​ Perform forward propagation to compute $a^{(l)}$ for $l=2,3,\cdots,L$ ​ Compute $\delta^{(L)},\delta^{(L-1)},\delta^{(L-2)},\cdots,\delta^{(2)}$ ​ $\Delta_{ji}^{(l)}:=\Delta_{ji}^{(l)}+a_j^{(l)}\delta_{i}^{(l+1)}$ Step 4 Computer $D_{ji}^{(l)}$: ​ $D_{ji}^{(l)}=\frac{1}{M}(\Delta_{ji}^{(l)}+\lambda\Theta_{ji}^{(l)})$ if $i\neq0$ ​ $D_{ji}^{(l)}=\frac{1}{M}\Delta_{ji}^{(l)}$ if $i=0$ 其中 $\delta^{(l)}$ 的计算如下： \delta^{(4)}=a^{(4)}-y\\ \delta^{(3)}=\left(\Theta^{(3)}\right)^{T} \delta^{(4)} \cdot * g^{\prime}\left(z^{(3)}\right)\\ \delta^{(2)}=\left(\Theta^{(2)}\right)^{T} \delta^{(3)} \cdot * g^{\prime}\left(z^{(2)}\right)计算图及公式推导 要正确理解 BP 算法，有两种方法，一种是基于数学式，一种是基于计算图。前者是比较常见的方法，该方法严密简洁且合理，但如果一上来就围绕数学式进行探讨，会忽略一些根本的东西[2]。但笔者认为，只根据计算图进行理解，不利于后续的编程计算。因而本文将二者相结合进行算法的推导。 计算图按照图中的数据类型可分为两类：标量计算图和矩阵计算图。 标量计算图对于标量计算图，根据链式法则可以得到下图所示的结果： 图2 标量计算图在该图中，为使表示清晰，我们省略了反向传播的箭头。以箭头上方的数字表示正向传播的数值，箭头下方的为反向传播的数值。 矢量计算图1对于矢量计算图，涉及到标量对矩阵的导数[3]，输出层的计算图如图3。 图3 矩阵计算图1计算推导过程如下： 若不考虑正则化，样本数量为 $M$ 时的总损失函数的矢量化形式为 J'=-y^Tlog(a^{(4)})+(\mathbf{1}-y)^Tlog(\mathbf{1}-a^{(4)})其中， $\mathbf{1}$ 为元素全为1的与 $y$ 尺寸相同的矩阵, $tr(A)$ 表示矩阵 $A$ 的迹。这里的总损失函数 $J’=J\cdot M$ 。 \mathrm{d}J'=-tr\left[y^T\frac{\mathrm{d}a^{(4)}}{a^{(4)}}-(\mathbf{1}-y)^T\frac{\mathrm{d}a^{(4)}}{a^{(4)}}\right]=tr\left\{\left[(\frac{\mathbf{1}-y}{\mathbf{1}-a^{(4)}})^T-(\frac{y}{a^{(4)}})^T\right]\mathrm{d}a^{(4)}\right\}故有 \frac{\partial J’}{\partial a^{(4)}}=\frac{\mathbf{1}-y}{\mathbf{1}-a^{(4)}}-\frac{y}{a^{(4)}}进而 \delta^{(4)}=\frac{\partial J’}{\partial z^{(4)}}=\frac{\partial J’}{\partial a^{(4)}}\frac{\partial a^{(4)}}{\partial z^{(4)}}=\left(\frac{\mathbf{1}-y}{\mathbf{1}-a^{(4)}}-\frac{y}{a^{(4)}}\right)\odot a^{(4)}\odot (1-a^{(4)})=a^{(4)}-y式中，符号 $\odot$ 为逐元素乘法。 由此，得到如图3所示的计算图。 矢量计算图2按照矢量计算图1的思路，继续反向传播，以正向传播中的 ${z^{(4)}=\Theta^{(3)} a^{(3)}}$ 为例，我们给出如下计算图： 图4 矩阵计算图2计算推导过程如下： \mathrm{d}J'=tr(\frac{\partial J'}{\partial z^{(4)}}^T\mathrm{d}z^{(4)})=tr(\frac{\partial J'}{\partial z^{(4)}}^T\mathrm{d}\Theta^{(3)}\cdot a^{(3)})=tr(a^{(3)}\frac{\partial J'}{\partial z^{(4)}}^T\mathrm{d}\Theta^{(3)})故有 \frac{\partial J'}{\partial \Theta^{(3)}}=\frac{\partial J'}{\partial z^{(4)}}(a^{(3)})^T=\delta^{(4)}(a^{(3)})^T类似地，有 \frac{\partial J'}{\partial a^{(3)}}=(\Theta^{(3)})^T\frac{\partial J'}{\partial z^{(4)}}=(\Theta^{(3)})^T\delta^{(4)}进而 \delta^{(3)}=\frac{\partial J’}{\partial z^{(3)}}=\frac{\partial J'}{\partial a^{(3)}}\frac{\partial a^{(3)}}{\partial z^{(3)}}=(\Theta^{(3)})^T\delta^{(4)}\odot a^{(3)}\odot (1-a^{(3)})以此类推，有 \delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}\odot a^{(2)}\odot (1-a^{(2)})从以上的推导中可以发现， $\delta^{(l)}$ 的定义为总损失函数对 $z^{(l)}$ 的偏导数，即 \delta^{(l)}=\frac{\partial J'}{\partial z^{(l)}}由此自然可以得到 \Delta:=\Delta+\delta^{(l+1)}(a^{(l)})^T这就是算法描述中的 $\Delta_{ji}^{(l)}$ 表达的矢量化表达。 若考虑正则化和损失函数的平均值 $J=J’/M$ ，自然有算法描述中的 D_{ji}^{(l)}=\frac{1}{M}(\Delta_{ji}^{(l)}+\lambda\Theta_{ji}^{(l)}),i\neq0\\ D_{ji}^{(l)}=\frac{1}{M}\Delta_{ji}^{(l)},i=0需要注意的是，由于前向传播时，每到下一层节点时，总是先添加偏置项（$a_0^{(1)},a_0^{(2)},a_0^{(3)}$）再正向传播计算对应的（$z^{(2)},z^{(3)},z^{(4)}$），所以在反向传播时得到（$\delta^{(3)},\delta^{(2)}$）时应去掉第一个元素再进行反向传播。一般地，应去调（$\delta^{(l-1)},\delta^{(l-2)},\cdots,\delta^{(l-1)}$）中的第一个元素再进行反向传播。这一做法按照计算图是十分易于理解的。 经过以上推导，我们对 BP 算法的反向传播过程有了更加深入的了解，也加深了对算法描述中的内容的理解。 注解 斋藤康毅《深度学习入门》一书中，输出层的激活函数为 softmax ,而损失函数采用了交叉熵误差函数，可以证明，这两个函数得到的效果与 Coursera 中输出层采用 sigmoid 函数和相应损失函数的效果是一致的，都是使 $\delta^{(4)}=a^{(4)}-y$ 成立，也就是将”误差“返回给上一层（过程见矩阵求导术（上）例6解2）。这样的”漂亮“结果是针对问题特意设计得到的。 关于算法描述的证明，可以用标量的形式，与矩阵形式的证明同理，过程稍显繁琐，具体过程可参考斋藤康毅《深度学习入门》一书第 5 章及附录。 参考文献[1] Andrew Ng 的 Coursera 课程 Machine Learning [2] 斋藤康毅.深度学习入门:基于Python的理论与实现.北京:人民邮电出版社,2018.121~161 [3] 长驱鬼侠的知乎专栏.矩阵求导术（上）]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beamer制作幻灯片时分文件编译]]></title>
    <url>%2F2019%2F10%2F05%2FBeamer%E5%88%B6%E4%BD%9C%E5%B9%BB%E7%81%AF%E7%89%87%E6%97%B6%E5%88%86%E6%96%87%E4%BB%B6%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[在用 Beamer 制作幻灯片的过程中，如果页数或者图片过多，往往造成 LaTeX 编译速度慢的问题。此时，如果能够分文件进行编译查看效果，最后插入到主文件中编译，制作幻灯片的效率势必大大提高。本文主要介绍Beamer制作幻灯片时分文件编译的方法。 Beamer 简介Beamer 是一个用于创建演示文稿 LaTeX 的文档类。Beamer 创建演示文稿相对于 PowerPoint 来说，优点在于简介大方，同时也有很多可直接运用的美观的模板，适合于数学公式较多的学术演示，移植性较好；缺点是不如 PowerPoint 那样直观灵活，动画支持较差，多图片排版较繁琐，播放时需要如 Adobe Reader 之类的阅读器。 网络上的Beamer教程较多，本文不再赘述其基本用法。更多关于 Beamer 作展示的利弊讨论参考 Why should I use LaTeX for presentations? 总之， Beamer 较适用于数学公式较多、图片较少，注重内容的学术展示。 关于可用的 Beamer 版式主题和颜色主题，这个 网站 给出了二者的组合，可以在比较后选择喜欢的用 \usetheme{} 引用版式主题，用 usecolortheme{} 引用颜色主题。 Beamer 分文件编译这里我们介绍利用 Beamer 分文件编译的一种方法。参考了 StackExchange 上的 这篇帖子 。基本思路是利用 Tomasz M. Trzeciak 编写的 docmute 包，该包文档参考 The docmute package 。 我的环境配置是 TeX Live 2017 + TeX Studio 2018 。 首先，我们打开 TeX Studio 新建一个主文件 main.tex ，内容如下： 12345678910111213141516\documentclass&#123;ctexbeamer&#125;\usepackage&#123;filecontents&#125;\begin&#123;filecontents*&#125;&#123;main.tex,pg1.tex&#125;\documentclass&#123;beamer&#125;\begin&#123;document&#125;\begin&#123;frame&#125; 世界！\end&#123;frame&#125;\end&#123;document&#125;\end&#123;filecontents*&#125;\usepackage&#123;docmute&#125;\begin&#123;document&#125;\input&#123;main&#125;\input&#123;pg1&#125;\end&#123;document&#125; 然后，我们新建一个名为 pg1 的子文件： 123456\documentclass&#123;ctexbeamer&#125;\begin&#123;document&#125;\begin&#123;frame&#125; 你好！\end&#123;frame&#125;\end&#123;document&#125; 此时，主文件和子文件均可独立编译。在 TeX Studio 中的具体方法是 主文件：直接编译即可； 子文件：先将子文件设置为主文档，再编译就是只编译子文件得到的效果。设置主文档方法如下图。 编译主文件得到效果如下： 只编译子文件得到效果如下： 由此，我们可以将 Beamer 分为若干个 Section （一般为3~5个比较好），分别制作每个部分的子文后编译查看效果，若内容和排版均符合要求，即可编译主文件。这样一方面节省了编译时间，另一方面也提高了代码的可读性，提高了工作效率。 参考资料 Beamer 版式和颜色主题组合 Beamer 的应用场景 Beamer 分文件编译的方法 docmute 包源码文档]]></content>
      <categories>
        <category>程序语言</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10上GPU版PyTorch的环境配置]]></title>
    <url>%2F2019%2F09%2F25%2Fwin10%E4%B8%8AGPU%E7%89%88PyTorch%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[本文主要解决Win10系统上GPU版PyTorch的环境配置问题。 检查配置按 Win+X 键打开设备管理器，找到显示适配器，查看自己电脑的显卡配置，如下图所示。 我的电脑是NVIDIA GeForce GTX 960M的显卡。 更新驱动打开NVIDIA官网更新驱动，选择第一步检查的自己电脑的配置。以我的电脑为例，依次为选择“GeForce”，“GeForce 900M Series (Notebooks)”，”GeForce GTX 960M”，“Windows 10 64-bit”，其他不做改动。点击“Search”后，点击“DOWNLOAD”进行下载。 下载后进行安装，安装过程中安装路径可自定义，选择“只安装图形驱动程序”即可。此过程从略。 用conda安装利用conda安装GPU版PyTorch的好处是，利用Anaconda包管理器安装cudatoolkit，避免了分别安装CUDA和cuDNN的不便。Anaconda包管理器的安装及基本用法可参见其他教程，此处从略。 打开Anaconda Promt，执行conda create -n pt1 python=3.6 spyder，创建环境pt1。 打开PyTorch官网，根据自己的系统配置进行选择，如下图所示。 上图是我电脑的选择。在刚刚建立的环境pt1中运行“Run this Command”对应的命令 1conda install pytorch torchvision cudatoolkit=9.2 -c pytorch -c defaults -c numba/label/dev 此过程较为耗时，等待全过程安装完毕。 测试安装完毕后，在pt1环境中打开Spyder，即，可在开始菜单单击“Spyder(pt1)”。 在Ipython中输入 123from __future__ import print_functionimport torch as tprint(t.cuda.is_available()) 若输出为True，则表明安装配置成功。 参考资料 PyTorch官网 NVIDIA驱动更新 PyTorch 1.0 中文文档&amp;教程]]></content>
      <categories>
        <category>程序语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在开头]]></title>
    <url>%2F2019%2F09%2F25%2F%E5%86%99%E5%9C%A8%E5%BC%80%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[“万事开头难。”历时3天，终于把个人博客捣鼓了出来。我采用的是GitHub+Hexo的搭建方式，NexT.Gemini主题，Gitalk评论插件。 在搭建过程中，我参考了网上很多的教程，此处特别感谢Zhechen’s Personal Website和韦阳的博客，让我的搭建过程少走了很多弯路。另外，官网Hexo和主题官网NexT也给了我很多帮助。 作为一名理工科的学生，我会通过博客，记录一些学习笔记和自认为有意义、有意思的事情。在帮助自己加深印象的同时，也希望能给同样寻求答案的人一些帮助。 我发现，网络上的博客质量参差不齐。希望我的博客能够始终保持高质量。既然写，就要写好、写清楚。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
